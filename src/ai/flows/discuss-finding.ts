
'use server';
console.error('üî•üî•üî• DISCUSS-FINDING EJECUT√ÅNDOSE üî•üî•üî•');
import { z } from 'zod';
import { type FindingWithStatus } from './compliance-scoring';
import { ai } from '@/ai/genkit';
import { type GenerateRequest } from 'genkit';

// Model configuration
const MODELS = {
  primary: 'anthropic/claude-sonnet-4-5-20250929',
  fallback: 'googleai/gemini-2.5-pro',
} as const;

// Schemas
const DiscussionMessageSchema = z.object({
  role: z.enum(['user', 'assistant']),
  content: z.string(),
});
export type DiscussionMessage = z.infer<typeof DiscussionMessageSchema>;

const DiscussFindingInputSchema = z.object({
  finding: z.any().describe("The full finding object that is being discussed."),
  history: z.array(DiscussionMessageSchema).describe("The history of the conversation so far."),
});
export type DiscussFindingInput = z.infer<typeof DiscussFindingInputSchema>;

const DiscussFindingOutputSchema = z.object({
  reply: z.string().describe("The assistant's argumentative and professional reply."),
  outcome: z.enum(['user_wins', 'ai_wins', 'ongoing']).optional().describe("Result of the discussion"),
  suggestedModuleInstruction: z.string().optional().describe("New instruction to add to module if user wins"),
  confidence: z.number().min(0).max(1).optional().describe("AI confidence in its position"),
});
export type DiscussFindingOutput = z.infer<typeof DiscussFindingOutputSchema>;

// Helper function to generate with fallback
async function generateWithFallback(request: GenerateRequest): Promise<string> {
  try {
    // Try primary model (Claude)
    const primaryRequest = { ...request, model: MODELS.primary };
    console.log('Calling Claude API...');
    const response = await ai.generate(primaryRequest);
    return response.text;
  } catch (primaryError) {
    console.warn('Primary model (Claude) failed, trying fallback (Gemini):', primaryError);
    // Fallback to Gemini
    const fallbackRequest = { ...request, model: MODELS.fallback };
    console.log('Calling Gemini API (fallback)...');
    const response = await ai.generate(fallbackRequest);
    return response.text;
  }
}

// Funci√≥n principal usando Claude con fallback a Gemini
export async function discussFinding(input: DiscussFindingInput): Promise<DiscussFindingOutput> {
  try {
    console.log('=== DEBUGGING discussFinding (Claude) ===');
    console.log('History length:', input.history?.length);

    if (!input.history || input.history.length === 0) {
      return {
        reply: 'Para iniciar la discusi√≥n sobre este hallazgo, presenta tu argumento o punto de vista sobre por qu√© consideras que esta incidencia no deber√≠a aplicar.'
      };
    }

    const lastMessage = input.history[input.history.length - 1];
    if (lastMessage.role !== 'user') {
      return {
        reply: 'Espero tu argumento para poder responder y discutir este hallazgo contigo.'
      };
    }
    console.log('User message:', lastMessage.content);

    const systemPrompt = `Se ha detectado la siguiente incidencia: "${input.finding.titulo_incidencia}".
El usuario argumenta: "${lastMessage.content}".

CONTEXTO DEL HALLAZGO ORIGINAL:
- Evidencia: "${input.finding.evidencia}"
- Justificaci√≥n Legal: ${input.finding.justificacion_legal}
- Justificaci√≥n T√©cnica: ${input.finding.justificacion_tecnica}
- Normativa: ${input.finding.nombre_archivo_normativa}, art√≠culo ${input.finding.articulo_o_seccion}
- Consecuencias Estimadas: ${input.finding.consecuencia_estimada}

TU ROL:
Eres un auditor profesional que eval√∫a argumentos de forma objetiva e imparcial. Tu objetivo NO es defender el hallazgo a toda costa, sino determinar si el argumento del usuario tiene m√©rito.

CRITERIOS PARA ACEPTAR EL ARGUMENTO DEL USUARIO (si cumple AL MENOS UNO):
1. Presenta evidencia documental concreta que contradice el hallazgo
2. Cita art√≠culos espec√≠ficos de normativa que excepcionan el caso
3. Demuestra un contexto operacional especial legalmente justificado
4. Presenta jurisprudencia o doctrina aplicable que respalda su posici√≥n
5. Identifica un error factual en el hallazgo original

INSTRUCCIONES DE RESPUESTA:
- Mant√©n un tono profesional y colaborativo.
- Si el argumento del usuario es S√ìLIDO y cumple alguno de los criterios anteriores, RECON√ìCELO claramente y acepta que el hallazgo debe ser eliminado.
- Si el argumento es parcialmente v√°lido pero incompleto, indica qu√© informaci√≥n adicional necesitas.
- Si el argumento es d√©bil o sin fundamento, explica por qu√© el hallazgo se mantiene.
- S√© conciso: responde en un m√°ximo de 150 palabras.`;

    const messagesForApi = input.history.map(msg => ({
      role: msg.role === 'assistant' ? 'model' : 'user',
      parts: [{ text: msg.content }],
    }));

    const request: GenerateRequest = {
      model: MODELS.primary, // Will be overwritten by generateWithFallback
      prompt: '',
      config: {
        temperature: 0.7,
        maxOutputTokens: 300,
      },
      history: messagesForApi.slice(0, -1),
      systemInstruction: systemPrompt,
    };

    const lastUserMsg = messagesForApi[messagesForApi.length-1];
    if(lastUserMsg) {
      request.prompt = lastUserMsg.parts[0].text || '';
    }

    const reply = await generateWithFallback(request);

    console.log('Response length:', reply.length);
    console.log('Response preview:', reply.substring(0, 100) + '...');

    return { reply };

  } catch (error: unknown) {
    console.error('=== ERROR in discussFinding ===');
    console.error('Error type:', error?.constructor?.name);
    console.error('Error message:', error instanceof Error ? error.message : String(error));
    console.error('Full error:', error);

    const fallbackResponse = `Ocurri√≥ un error al contactar al asistente de IA. Por favor, revisa la configuraci√≥n y tu conexi√≥n a internet.`;

    return { reply: `[FALLBACK] ${fallbackResponse}` };
  }
}

/**
 * Eval√∫a si el argumento del usuario es suficientemente s√≥lido para ganar la discusi√≥n
 */
async function evaluateUserArgument(
  finding: FindingWithStatus,
  userArgument: string
): Promise<{ userWins: boolean; confidence: number; reason: string }> {
  try {
    const evaluationPrompt = `Eres un juez imparcial en una discusi√≥n sobre compliance normativo.

HALLAZGO ORIGINAL:
- T√≠tulo: ${finding.titulo_incidencia}
- Gravedad: ${finding.gravedad}
- Evidencia: "${finding.evidencia}"
- Justificaci√≥n legal: ${finding.justificacion_legal}
- Normativa: ${finding.nombre_archivo_normativa}, art. ${finding.articulo_o_seccion}

ARGUMENTO DEL USUARIO:
"${userArgument}"

Eval√∫a si el argumento del usuario es suficientemente s√≥lido para DESESTIMAR y ELIMINAR el hallazgo.

CRITERIOS PARA QUE EL USUARIO GANE (si cumple AL MENOS UNO, userWins=true):
1. Presenta evidencia documental concreta que contradice el hallazgo
2. Cita art√≠culos espec√≠ficos de normativa que excepcionan el caso
3. Demuestra un contexto operacional especial legalmente justificado
4. Presenta jurisprudencia o doctrina aplicable que respalda su posici√≥n
5. Identifica un error factual en el hallazgo original

IMPORTANTE: S√© justo y objetivo. Si el usuario presenta un argumento v√°lido y bien fundamentado, recon√≥celo con userWins=true y confidence alta.

Responde en JSON:
{
  "userWins": boolean,
  "confidence": number (0-1),
  "reason": "explicaci√≥n breve de por qu√© gana o no el usuario"
}`;

    const reply = await generateWithFallback({
      model: MODELS.primary,
      prompt: evaluationPrompt,
      config: {
        temperature: 0.3,
        maxOutputTokens: 500,
      },
    });

    const result = JSON.parse(reply);
    return {
      userWins: result.userWins || false,
      confidence: result.confidence || 0,
      reason: result.reason || '',
    };
  } catch (error) {
    console.error('Error evaluating user argument:', error);
    return { userWins: false, confidence: 0, reason: 'Error en evaluaci√≥n' };
  }
}

/**
 * Genera una nueva instrucci√≥n para el m√≥dulo basada en el argumento ganador del usuario
 */
async function generateModuleInstruction(
  finding: FindingWithStatus,
  userArgument: string
): Promise<string> {
  try {
    const instructionPrompt = `Bas√°ndote en el siguiente caso donde el usuario gan√≥ la discusi√≥n, genera una instrucci√≥n concisa para agregar al m√≥dulo de validaci√≥n que evite futuros falsos positivos similares.

HALLAZGO ORIGINAL (FALSO POSITIVO):
- T√≠tulo: ${finding.titulo_incidencia}
- Evidencia: "${finding.evidencia}"
- Normativa: ${finding.nombre_archivo_normativa}, art. ${finding.articulo_o_seccion}

ARGUMENTO GANADOR DEL USUARIO:
"${userArgument}"

Genera una instrucci√≥n clara, espec√≠fica y accionable (m√°ximo 150 palabras) que se agregar√° a las instrucciones del m√≥dulo.

Formato:
"En casos donde [contexto espec√≠fico], NO marcar como hallazgo si [condici√≥n], debido a [justificaci√≥n legal/t√©cnica]."

Ejemplo:
"En casos donde se solicite la presentaci√≥n de garant√≠as bancarias, NO marcar como hallazgo si el pliego especifica modalidades alternativas de garant√≠a (p√≥lizas de seguro de cauci√≥n, fianzas), debido a que el art. 123 de la Ley 80/93 permite garant√≠as equivalentes."

Genera solo la instrucci√≥n, sin pre√°mbulos.`;

    const reply = await generateWithFallback({
      model: MODELS.primary,
      prompt: instructionPrompt,
      config: {
        temperature: 0.4,
        maxOutputTokens: 300,
      },
    });

    return reply.trim();
  } catch (error) {
    console.error('Error generating module instruction:', error);
    return '';
  }
}

/**
 * Guarda una nueva instrucci√≥n en el m√≥dulo del usuario
 */
async function saveModuleInstruction(
  userId: string,
  moduleId: string,
  instruction: string
): Promise<void> {
  try {
    // Por ahora guardamos en localStorage, luego ser√° en BD
    const storageKey = `module-instructions-${userId}-${moduleId}`;
    const existing = localStorage.getItem(storageKey);
    const instructions = existing ? JSON.parse(existing) : [];

    instructions.push({
      instruction,
      createdAt: new Date().toISOString(),
      source: 'discussion_win',
    });

    localStorage.setItem(storageKey, JSON.stringify(instructions));
    console.log('‚úÖ Module instruction saved:', instruction);
  } catch (error) {
    console.error('Error saving module instruction:', error);
  }
}

// Server Action for the client component
export async function discussFindingAction(
  history: DiscussionMessage[],
  finding: FindingWithStatus
): Promise<{
  reply: string;
  outcome?: 'user_wins' | 'ai_wins' | 'ongoing';
  suggestedModuleInstruction?: string;
}> {
    try {
        console.log('Starting discussFindingAction with Genkit/Gemini');

        if (!history || history.length === 0) {
            return {
                reply: "Para iniciar la discusi√≥n sobre este hallazgo, presenta tu argumento o punto de vista sobre por qu√© consideras que esta incidencia no deber√≠a aplicar o requiere modificaci√≥n.",
                outcome: 'ongoing',
            };
        }

        const lastUserMessage = history[history.length - 1];
        if (lastUserMessage.role !== 'user') {
            return {
                reply: "Espero tu argumento para poder responder y discutir este hallazgo contigo.",
                outcome: 'ongoing',
            };
        }

        // Si es el segundo mensaje del usuario o posterior, evaluamos si puede ganar
        const userMessages = history.filter(m => m.role === 'user');
        if (userMessages.length >= 2) {
            const evaluation = await evaluateUserArgument(finding, lastUserMessage.content);

            if (evaluation.userWins && evaluation.confidence > 0.6) {
                // El usuario gan√≥ la discusi√≥n - el hallazgo ser√° eliminado
                const instruction = await generateModuleInstruction(finding, lastUserMessage.content);

                return {
                    reply: `**Hallazgo eliminado.** Tu argumento es v√°lido y bien fundamentado.\n\n**Raz√≥n:** ${evaluation.reason}\n\nEste hallazgo ha sido removido del an√°lisis. Adem√°s, se ha generado una nueva instrucci√≥n para el m√≥dulo que evitar√° este tipo de falsos positivos en futuros an√°lisis.`,
                    outcome: 'user_wins',
                    suggestedModuleInstruction: instruction,
                };
            }
        }

        // Continuar la discusi√≥n normalmente
        const result = await discussFinding({ history, finding });

        return {
            reply: result.reply,
            outcome: result.outcome || 'ongoing',
            suggestedModuleInstruction: result.suggestedModuleInstruction,
        };

    } catch (error: unknown) {
        console.error('Error in discussFindingAction:', error);
        
        const lastMessage = history && history.length > 0 ? history[history.length - 1] : null;
        const userContent = lastMessage && lastMessage.role === 'user' ? lastMessage.content : 'su argumento';
        
        const manualResponse = `Comprendo tu punto sobre "${userContent}". Sin embargo, el hallazgo "${finding.titulo_incidencia}" se mantiene v√°lido seg√∫n ${finding.nombre_archivo_normativa}, art√≠culo ${finding.articulo_o_seccion}.

${finding.justificacion_legal}

Para cambiar esta evaluaci√≥n, necesito una base legal espec√≠fica. ¬øPuedes citar art√≠culos de la normativa que respalden tu posici√≥n?`;

        return {
            reply: manualResponse,
            outcome: 'ongoing',
        };
    }
}
